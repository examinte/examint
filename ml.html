<pre>
	<h1>program 1</h1>
import csv

num_attributes=6
a=[]

with open("enjoysportml.csv",'r') as csvfile:
reader=csv.reader(csvfile)
for row in reader:
    a.append(row)
    print(row)

print("\n The initial value of hypothesis:")
hypothesis=['0']*num_attributes
print(hypothesis)

hypothesis=a[1]
print("\n Find S:Finding a maximally specific hypothesis\n")
print(hypothesis)

for i in range(2,len(a)):
    if a[i][num_attributes]=='Yes':
        for j in range(0,num_attributes):
            if a[i][j]!=hypothesis[j]:
                hypothesis[j]='?'
    print("For Training instance No:{0} the hypothesis".format(i),hypothesis)
    print("\n The maximally specific hypothesis for a given training examples:\n")
    print(hypothesis)

<h1>program2</h1>

import csv

with open("enjoysportml.csv")as f:
    csv_file=csv.reader(f)
    data=list(csv_file)
    print(data)
    s=data[1][:-1]
    g=[['?'for i in range(len(s))]for j in range(len(s))]
    for i in data:
        if i[-1]=="Yes":
            for j in range(len(s)):
                if i[j]!=s[j]:
                    s[j]='?'
                    g[j][j]='?'
        elif i[-1]=="No":
            for j in range(len(s)):
                if i[j]!=s[j]:
                    g[j][j]=s[j]
                else:
                    g[j][j]="?"
    print("\nsteps of candidate elimination algorithm" ,data.index(i))
    print(s)
    print(g)
    gh=[]
    for i in g:
        for j in i:
            if j!='?':
                gh.append(i)
                break
    print("\nfinal specific hypothisis:\n",s)
    print("\nfinal specific hypothisis:\n",gh)
           

<h1>program 3</h1> 

import pandas as pd
import numpy
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score
import joblib

data=pd.read_csv("covid_ml.csv")
data.head()

data.replace({'Fever':{'No':0,'Yes':1},'Cough':{'No':0,'Yes':1},'Breathing_issues':{'No':0,'Yes':1},'Infected':{'No':0,'Yes':1}},inplace=True)

x=data.drop(columns=['ID','Infected'],axis=1)
y=data['Infected']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

model=DecisionTreeRegressor()

model.fit(x_train,y_train)

y_train_prediction=model.predict(x_test)

training_data_accuracy=r2_score(y_test,y_train_prediction)
print('Accuracy score of training data: ',training_data_accuracy)

joblib.dump(model,'DecisionTree')
predictor=joblib.load('DecisionTree')
predictor.predict(x_test)

new_data=pd.DataFrame({
    'Fever':0,
    'Cough':0,
    'Breathing_issues':1
},index=[0])

ans=predictor.predict(new_data)
if ans==0:
    print("no")
else:
    print("yes")

<h1>program3b</h1>

import csv
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from six import StringIO
data = pd.read_csv('Playtennis.csv')
print("The first 5 values of data is \n",data.head())

X = data.iloc[:,1:-1]
print("\nThe first 5 values of Train data is \n",X.head())
y = data.iloc[:,-1]
print("\nThe first 5 values of Train output is \n",y.head())

le_outlook = LabelEncoder()
X.Outlook = le_outlook.fit_transform(X.Outlook)
le_Temperature = LabelEncoder()
X.Temp = le_Temperature.fit_transform(X.Temp)
le_Humidity = LabelEncoder()
X.Humidity = le_Humidity.fit_transform(X.Humidity)
le_Windy = LabelEncoder()
X.Wind = le_Windy.fit_transform(X.Wind)
print("\nNow the Train data is")
print(X.head())
le_PlayTennis = LabelEncoder()
y = le_PlayTennis.fit_transform(y)
print("\nNow the Train data is\n",y)
classifier = DecisionTreeClassifier()
classifier.fit(X,y)
def labelEncoderForInput(list1):
  list1[0] = le_outlook.transform([list1[0]])[0]
  list1[1] = le_Temperature.transform([list1[1]])[0]
  list1[2] = le_Humidity.transform([list1[2]])[0]
  list1[3] = le_Windy.transform([list1[3]])[0]
  return [list1]

#inp = ["Rain","Mild","High","Weak"]
inp=["Rain","Cool","High","Weak"]
inp1 = inp.copy()
pred1 = labelEncoderForInput(inp)
y_pred = classifier.predict(pred1)
print(inp1)
print("OUTPUT IS")
print(y_pred)
print("\nfor input {0}, we obtain {1}".format(inp1,
le_PlayTennis.inverse_transform(y_pred)))
y_pred_all = classifier.predict(X)
cm = confusion_matrix(y, y_pred_all)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le_PlayTennis.classes_)

disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()
	
<h1>program 4</h1>

import numpy as np

#Dataset
X = np.array([[0.35, 0.9]], dtype = float)
y = np.array([[0.5]], dtype = float)
print(X)

#Sigmoid Function (Activation Function)
def sigmoid(x):
    return 1/(1 + np.exp(-x))

#Variable initialization
epoch = 100
learning_rate = 1
ip_neurons = 2
hidden_neurons = 2
op_neurons = 1

#Weight and Bias Initialization
wh = np.random.uniform(size = (ip_neurons, hidden_neurons))
bh = np.random.uniform(size = (1, hidden_neurons))
wout = np.random.uniform(size = (hidden_neurons, op_neurons))
bout = np.random.uniform(size = (1, op_neurons))

#draws a random range of numbers uniformly of dim x*y
for i in range(epoch):
    #1. Forward Propogation
    hinp1 = np.dot(X, wh)
    hinp = hinp1 + bh
    hlayer_act = sigmoid(hinp)
    outinp1 = np.dot(hlayer_act, wout)
    outinp = outinp1 + bout
    output = sigmoid(outinp)
    #2. Backpropagation
    d_output = (y - output) * output * (1 - output)
    # hidden layer wts contributed to error
    d_hiddenlayer = d_output.dot(wout.T) * (hlayer_act) * (1 - hlayer_act)

    #3. adjust Weight and bias
    wout = wout + hlayer_act.T.dot(d_output) * learning_rate # delta*output*learning rate
    wh = wh + X.T.dot(d_hiddenlayer) * learning_rate
    print("-----------Epoch-", i + 1)
    print("Input: \n" + str(X) + "Actual Output: \n" + str(y) + "Predicted Output: \n", output)
print("Input: \n" + str(X) + "Actual Output: \n" + str(y) + "Final Predicted Output: \n", output)

<h1>program 5</h1>

import pandas as pd
from sklearn import tree
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB

data =pd.read_csv('PlayTennis.csv')
print("The first 5 Values of data is :\n", data.head())

from sklearn.preprocessing import LabelEncoder
edc=LabelEncoder()
data=data.apply(LabelEncoder().fit_transform)
data.head()

X = data.iloc[:, :-1]
print("\nThe First 5 values of the train data is\n", X.head())
y = data.iloc[:, -1]
print("\nThe First 5 values of train output is\n", y.head())
le_PlayTennis = LabelEncoder()
y = le_PlayTennis.fit_transform(y)
print("\nNow the Train output is\n",y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20)
classifier = GaussianNB()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
accuray = accuracy_score(y_pred, y_test)
f1 = f1_score(y_pred, y_test, average="weighted")
print("Accuracy:", accuray)
print("F1 Score:", f1)
labels = ["Play Yes", "Play No"]
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot()

<h1>program 6</h1>

pip install pgmpy

import numpy as np
import pandas as pd
from pgmpy.estimators import MaximumLikelihoodEstimator
from pgmpy.models import BayesianNetwork
from pgmpy.inference import VariableElimination

# Load the heart disease dataset
heartDisease = pd.read_csv('heart.csv')

# Replace missing values represented by '?' with NaN
heartDisease = heartDisease.replace('?', np.nan)

# Display sample instances from the dataset
print('Sample instances from the dataset are given below')
print(heartDisease.head())

# Display attributes and their datatypes
print('\n Attributes and datatypes')
print(heartDisease.dtypes)

# Define the Bayesian Network structure
model = BayesianNetwork([
    ('age', 'heartdisease'),
    ('gender', 'heartdisease'),
    ('exang', 'heartdisease'),
    ('cp', 'heartdisease'),
    ('heartdisease', 'restecg'),
    ('heartdisease', 'chol')
])

# Print status
print('\nLearning CPD using Maximum likelihood estimators')

# Fit the model to the data
model.fit(heartDisease, estimator=MaximumLikelihoodEstimator)

# Print status
print('\n Inferencing with Bayesian Network:')

# Perform inference
HeartDiseasetest_infer = VariableElimination(model)

# Example queries
print('\n 1. Probability of HeartDisease given evidence= restecg')
q1 = HeartDiseasetest_infer.query(variables=['heartdisease'], evidence={'restecg': 1})
print(q1)

print('\n 2. Probability of HeartDisease given evidence= cp')
q2 = HeartDiseasetest_infer.query(variables=['heartdisease'], evidence={'cp': 2})
print(q2)

<h1>program 7</h1>

from sklearn.cluster import KMeans
from sklearn import preprocessing
from sklearn.mixture import GaussianMixture
from sklearn.datasets import load_iris
import sklearn.metrics as sm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

dataset=load_iris()
print(dataset)

X=pd.DataFrame(dataset.data)
X.columns=['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']
y=pd.DataFrame(dataset.target)
y.columns=['Targets']

plt.figure(figsize=(14,7))
colormap=np.array(['red','lime','black'])

plt.subplot(1,3,1)
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y.Targets],s=40)
plt.title('Real')

plt.subplot(1,3,2)
model=KMeans(n_clusters=3)
model.fit(X)
predY=np.choose(model.labels_,[0,1,2]).astype(np.int64)
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[predY],s=40)
plt.title('KMeans')

scaler=preprocessing.StandardScaler()
scaler.fit(X)
xsa=scaler.transform(X)
xs=pd.DataFrame(xsa,columns=X.columns)
gmm=GaussianMixture(n_components=3)
gmm.fit(xs)
y_cluster_gmm=gmm.predict(xs)
plt.subplot(1,3,3)
plt.scatter(X.Petal_Length,X.Petal_Width,c=colormap[y_cluster_gmm],s=40)
plt.title('GMM Classification')

<h1>program 8</h1>

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn import metrics
import pandas as pd
import numpy as np
from sklearn import datasets
iris=datasets.load_iris()
iris_data=iris.data
iris_labels=iris.target
print(iris_data)
x_train, x_test, y_train, y_test=(train_test_split(iris_data, iris_labels,
test_size=0.20))
classifier=KNeighborsClassifier(n_neighbors=6)
classifier.fit(x_train, y_train)
y_pred=classifier.predict(x_test)
print(y_pred)
print("accuracy is")
print(classification_report(y_test, y_pred))
print('Confusion Matrix')
cm = confusion_matrix(y_test,y_pred)
print(cm)
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

<h1>program 9</h1>

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

def kernel(point, xmat, k):
    m, n = np.shape(xmat)
    weights = np.mat(np.eye((m)))  # Return a 2-D array with ones on the diagonal and zeros elsewhere
    for j in range(m):
        diff = point - xmat[j]
        weights[j, j] = np.exp(diff * diff.T / (-2.0 * k**2))  # k is the smoothing parameter
    return weights

def localWeight(point, xmat, ymat, k):
    wei = kernel(point, xmat, k)
    W = (xmat.T * (wei * xmat)).I * (xmat.T * (wei * ymat.T))
    return W

def localWeightRegression(xmat, ymat, k):
    m, n = np.shape(xmat)
    ypred = np.zeros(m)
    for i in range(m):
        ypred[i] = xmat[i] * localWeight(xmat[i], xmat, ymat, k)
    return ypred

# Load data points
data = pd.read_csv('Hotel.csv')
bill = np.array(data.total_bill)
tip = np.array(data.tip)

# Preparing and add 1 in bill
mbill = np.mat(bill)
mtip = np.mat(tip)
m = np.shape(mbill)[1]
one = np.mat(np.ones(m))
X = np.hstack((one.T, mbill.T))

# Set k here
k = 0.5
ypred = localWeightRegression(X, mtip, k)
SortIndex = X[:, 1].argsort(0)
xsort = X[SortIndex][:, 0]

# Plotting
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
ax.scatter(bill, tip, color='green')
ax.plot(xsort, ypred[SortIndex], color='red', linewidth=5)
plt.xlabel('Total bill')
plt.ylabel('Tip')
plt.show()


<h1>program 10</h1>

from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.svm import SVC

 # Load the datasets
data=datasets.load_iris()
X = data.data[:, :2]
y = data.target

data

data.target

#Build the model
svm = SVC(kernel="rbf", gamma=0.5, C=1.0) #radial Bias Kernel
# Trained the model
svm.fit(X, y)

# Plot Decision Boundary
DecisionBoundaryDisplay.from_estimator(
svm,
X,
response_method="predict",
cmap=plt.cm.Spectral,
alpha=0.8,
xlabel=data.feature_names[0],
ylabel=data.feature_names[1],
)
# Scatter plot
plt.scatter(X[:, 0], X[:, 1],
c=y,
s=20, edgecolors="k")
plt.show()
</pre>
